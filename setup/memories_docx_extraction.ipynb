{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79075aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document as Doc\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02215b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          headline  \\\n",
      "0            ילדות ונעורים בפלונסק   \n",
      "1         עלייתי לארץ. מכתבים לאבא   \n",
      "2  חיי בסג'רה – עבודה ושמירה עברית   \n",
      "3  חללי סג'רה – עבודתי בזכרון-יעקב   \n",
      "4         מחקלאות לעתונות פועלים –   \n",
      "\n",
      "                                            document  \n",
      "0  נולדתי ביום י\"ז בתשרי תרמ\"ז (16.10.1886) בעייר...  \n",
      "1  ארבעתנו, שושקה, אשתו של שמחה אייזיק, ובתה רחל ...  \n",
      "2  אחרי יהודה היתה לי סג'רה כמעט מה שהיתה לי פתח-...  \n",
      "3  סג'רה שהיתה ראשונה לשמירה עברית היתה גם ראשונה...  \n",
      "4  מעתונות לפוליטיקה ולאוניברסיטה התורכית\\nעבדתי ...  \n"
     ]
    }
   ],
   "source": [
    "def is_chapter_number(text):\n",
    "    \"\"\"\n",
    "    Checks if the text is a single Hebrew letter (used as a chapter marker).\n",
    "    \"\"\"\n",
    "    return re.fullmatch(r'[א-ת]', text.strip())\n",
    "\n",
    "def docx_split_by_structured_titles(docx_path):\n",
    "    \"\"\"\n",
    "    Splits a .docx file into structured documents based on Hebrew chapter markers.\n",
    "\n",
    "    Each chapter starts with a single Hebrew letter (e.g., א) followed by a title line.\n",
    "    The function groups the subsequent paragraphs as the chapter body, until the next chapter begins.\n",
    "\n",
    "    Args:\n",
    "        docx_path (str): Path to the .docx file.\n",
    "        start_index (int): Optional index to start counting from (not currently used here).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with structured documents including 'headline', 'document', 'source', and 'book_id'.\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    documents = []\n",
    "    current_title = None\n",
    "    current_body = []\n",
    "    skip_next = False  # Used to skip the paragraph immediately after a chapter marker (it's the title)\n",
    "\n",
    "    for i in range(len(doc.paragraphs) - 1):\n",
    "        para = doc.paragraphs[i]\n",
    "        next_para = doc.paragraphs[i + 1]\n",
    "        text = para.text.strip()\n",
    "        next_text = next_para.text.strip()\n",
    "\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "\n",
    "        # Detect new chapter: current paragraph is a single Hebrew letter and next paragraph is non-empty (title)\n",
    "        if is_chapter_number(text) and next_text:\n",
    "            # Save the previous chapter if it exists\n",
    "            if current_title and current_body:\n",
    "                documents.append({\n",
    "                    \"headline\": re.sub(r\"^[א-ת]\\s*-\\s*\", \"\", current_title),\n",
    "                    \"document\": \"\\n\".join(current_body),\n",
    "                    \"source\": \"DBGH\",\n",
    "                    \"book_id\": \"memories\"\n",
    "                })\n",
    "                current_body = []\n",
    "\n",
    "            # Start a new chapter title\n",
    "            current_title = f\"{text} - {next_text}\"\n",
    "            skip_next = True\n",
    "        else:\n",
    "            if text:\n",
    "                current_body.append(text)\n",
    "\n",
    "    # Add the last chapter if needed\n",
    "    if current_title and current_body:\n",
    "        documents.append({\n",
    "            \"headline\": re.sub(r\"^[א-ת]\\s*-\\s*\", \"\", current_title),\n",
    "            \"document\": \"\\n\".join(current_body),\n",
    "            \"source\": \"DBGH\",\n",
    "            \"book_id\": \"memories\"\n",
    "        })\n",
    "    # Return the structured data as a DataFrame\n",
    "    df = pd.DataFrame(documents)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = docx_split_by_structured_titles('./data/memories.docx')\n",
    "print(df[['headline', \"document\"]].head())\n",
    "df.to_csv('./data/memories.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4afe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same text pre-processing steps used for the initial dataset\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags.\"\"\"\n",
    "    text = re.sub(r'<[^<]+?>', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s\\.,;:\\?\\'\\\"\\!\\-\\u0590-\\u05FF]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_repeated_substrings(text):\n",
    "    text = re.sub(r'([.?!,;:—\"])\\1+', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = remove_html_tags(text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = remove_special_characters(text)\n",
    "\n",
    "    # Remove repeated substrings like dots\n",
    "    text = remove_repeated_substrings(text)\n",
    "\n",
    "    # Remove extra spaces between lines and within lines\n",
    "    text = remove_extra_spaces(text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b23c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df.loc[:, 'document_pp'] = df['document'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4325f23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>document</th>\n",
       "      <th>source</th>\n",
       "      <th>book_id</th>\n",
       "      <th>document_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ילדות ונעורים בפלונסק</td>\n",
       "      <td>נולדתי ביום י\"ז בתשרי תרמ\"ז (16.10.1886) בעייר...</td>\n",
       "      <td>DBGH</td>\n",
       "      <td>memories</td>\n",
       "      <td>נולדתי ביום י\"ז בתשרי תרמ\"ז 16.10.1886 בעיירה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>עלייתי לארץ. מכתבים לאבא</td>\n",
       "      <td>ארבעתנו, שושקה, אשתו של שמחה אייזיק, ובתה רחל ...</td>\n",
       "      <td>DBGH</td>\n",
       "      <td>memories</td>\n",
       "      <td>ארבעתנו, שושקה, אשתו של שמחה אייזיק, ובתה רחל ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>חיי בסג'רה – עבודה ושמירה עברית</td>\n",
       "      <td>אחרי יהודה היתה לי סג'רה כמעט מה שהיתה לי פתח-...</td>\n",
       "      <td>DBGH</td>\n",
       "      <td>memories</td>\n",
       "      <td>אחרי יהודה היתה לי סג'רה כמעט מה שהיתה לי פתח-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>חללי סג'רה – עבודתי בזכרון-יעקב</td>\n",
       "      <td>סג'רה שהיתה ראשונה לשמירה עברית היתה גם ראשונה...</td>\n",
       "      <td>DBGH</td>\n",
       "      <td>memories</td>\n",
       "      <td>סג'רה שהיתה ראשונה לשמירה עברית היתה גם ראשונה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>מחקלאות לעתונות פועלים –</td>\n",
       "      <td>מעתונות לפוליטיקה ולאוניברסיטה התורכית\\nעבדתי ...</td>\n",
       "      <td>DBGH</td>\n",
       "      <td>memories</td>\n",
       "      <td>מעתונות לפוליטיקה ולאוניברסיטה התורכית עבדתי ב...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          headline  \\\n",
       "0            ילדות ונעורים בפלונסק   \n",
       "1         עלייתי לארץ. מכתבים לאבא   \n",
       "2  חיי בסג'רה – עבודה ושמירה עברית   \n",
       "3  חללי סג'רה – עבודתי בזכרון-יעקב   \n",
       "4         מחקלאות לעתונות פועלים –   \n",
       "\n",
       "                                            document source   book_id  \\\n",
       "0  נולדתי ביום י\"ז בתשרי תרמ\"ז (16.10.1886) בעייר...   DBGH  memories   \n",
       "1  ארבעתנו, שושקה, אשתו של שמחה אייזיק, ובתה רחל ...   DBGH  memories   \n",
       "2  אחרי יהודה היתה לי סג'רה כמעט מה שהיתה לי פתח-...   DBGH  memories   \n",
       "3  סג'רה שהיתה ראשונה לשמירה עברית היתה גם ראשונה...   DBGH  memories   \n",
       "4  מעתונות לפוליטיקה ולאוניברסיטה התורכית\\nעבדתי ...   DBGH  memories   \n",
       "\n",
       "                                         document_pp  \n",
       "0  נולדתי ביום י\"ז בתשרי תרמ\"ז 16.10.1886 בעיירה ...  \n",
       "1  ארבעתנו, שושקה, אשתו של שמחה אייזיק, ובתה רחל ...  \n",
       "2  אחרי יהודה היתה לי סג'רה כמעט מה שהיתה לי פתח-...  \n",
       "3  סג'רה שהיתה ראשונה לשמירה עברית היתה גם ראשונה...  \n",
       "4  מעתונות לפוליטיקה ולאוניברסיטה התורכית עבדתי ב...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426c2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe rows to LangChain Documents\n",
    "docs = [\n",
    "    Doc(page_content=row['document_pp'], metadata={\"book_id\": row['book_id'], \"headline\": row[\"headline\"] , \"source\": \"DBGH\"})\n",
    "    for idx, row in df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a9a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_by_words(text, max_words, overlap_words):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(words):\n",
    "        end_idx = min(start_idx + max_words, len(words))\n",
    "        chunk = words[start_idx:end_idx]\n",
    "\n",
    "        # Join the words back into text\n",
    "        chunk_text = ' '.join(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "        # Update the starting position with overlap\n",
    "        start_idx += max_words - overlap_words\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9e13f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "idx = 21529\n",
    "\n",
    "for doc in docs:\n",
    "    temp_chunks = split_text_by_words(\n",
    "        doc.page_content, max_words=260, overlap_words=35\n",
    "    )\n",
    "    \n",
    "    for chunk in temp_chunks:\n",
    "        new_metadata = dict(doc.metadata) \n",
    "        new_metadata['idx'] = idx \n",
    "        chunks.append(Doc(page_content=chunk, metadata=new_metadata))\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e1ece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee973fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/chunks.pkl', 'rb') as f:\n",
    "    initial_chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53606782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21529\n"
     ]
    }
   ],
   "source": [
    "print(len(initial_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ffb5e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21640\n"
     ]
    }
   ],
   "source": [
    "DBGH_chunks = initial_chunks + chunks\n",
    "print(len(DBGH_chunks))\n",
    "with open('./data/DBGH_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(DBGH_chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0923ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'book_id': 88632, 'headline': 'לקראת \"יציאת אירופה\" - מאמר מתוך סדרת מאמרים: בדרך לצבא ולמדינת ישראל', 'source': 'DBGH', 'idx': 21527}, page_content='תהיה פחות מדולדלת משאר המעצמות הנלחמות. רווחת אירופה תהיה תלויה במידה רבה בעזרתה הכלכלית של ארצות-הברית. ושמירת השלום, שכנראה תהיה הדאגה הראשית של על אהדת בריטניה לעצמאות סוריה. המדינות המנצחות, תהיה תלויה יותר מתמיד בהשתתפותה האקטיבית של אמריקה בסידורים החדשים שלאחר המלחמה. אבל מה שלא יהיה מעמדה של אמריקה בעניני העולם - בענינים שלנו היא בוודאי תהא מכרעת. באמריקה יהיה יותר קל לרכוש דעת-הקהל לפתרון רדיקלי ומכסימלי של הבעיה היהודית בארץישראל, מאשר באנגליה. אמריקה חופשית מהתסביך הערביהמוסלימי, ואם שירותה הקונסולרי במזרח התיכון עלול אולי להיות שותף לתפיסת הפקידות הבריטית במזרח התיכון, הרי השפעת שירות זה רחוקה מזו של משרדי החוץ והמושבות באנגליה. אמריקה היא בהרבה פחות מעוניינת בארץ-ישראל מאנגליה, ולכן היא מוכשרה לנקוט עמדה יותר אובייקטיבית ובלתי-משוחדת. יש לזכור גם זאת: יש בה עדה יהודית גדולה - הגדולה בעולם - שהיא מתעניינת בא\"י יהודית ואוהדת אותה, ואינה חסרת השפעה. ואם כי חלקים רבים של יהודי אמריקה אינם ציונים - הרי רק מעטים מתוכם הם אנטי-ציונים: מצד אחד הקומוניסטים, ומהצד השני מספר אישים מגדולי העשירים. ההמון הגדול של יהודי אמריקה מכל המעמדות מעוניין בבנין ארץ-ישראל, ואפשר לקוות בבטחה שהם יתייצבו מאחורי המאמצים הציוניים, אם אלה ייעשו ביעילות, בהתמדה ובאומץ-לב. ולמען רכוש דעת-הקהל באמריקה ובבריטניה מוטל עלינו לשכנע אותה בצדקת שאיפתנו, במעשיותה ובהכרחיותה, כפתרון האפשרי והשריר היחיד. עלינו להוכיח להם, שרק סידור טריטוריאלי רחב-מידות בארץ ישראל על-ידי עליה והתיישבות המונית, שתעשה את העם היהודי לעצמאי, בן-חורין ושוה-זכויות לכל עמים אחרים - יבטיח פתרון נאמן. ועלינו להוכיח שסידור טריטוריאלי זה ייתכן לבצע בארץישראל, ורק בארץישראל. זאת אומרת - כינון ארץ-ישראל כקומונוולט יהודי מיד לאחר המלחמה. לעם האמריקני יש לב פתוח להבין זאת. העולם'),\n",
       " Document(metadata={'book_id': 88632, 'headline': 'לקראת \"יציאת אירופה\" - מאמר מתוך סדרת מאמרים: בדרך לצבא ולמדינת ישראל', 'source': 'DBGH', 'idx': 21528}, page_content='לכל עמים אחרים - יבטיח פתרון נאמן. ועלינו להוכיח שסידור טריטוריאלי זה ייתכן לבצע בארץישראל, ורק בארץישראל. זאת אומרת - כינון ארץ-ישראל כקומונוולט יהודי מיד לאחר המלחמה. לעם האמריקני יש לב פתוח להבין זאת. העולם בכללו והדימוקרטיות הגדולות בייחוד יהיו בשלים אחרי מלחמת-עולם זו בשביל פתרונות נועזים ורבי-מידות לבעיות המציקות לעולם הנוכחי. תמיכת אמריקה במדינה יהודית היא המפתח הראשי להצלחתנו. יש רק גורם אחד, שהוא עוד יותר מכריע בעיצוב עתידנו מאשר אמריקה, וזהו הישוב היהודי בארץ-ישראל עצמה. מלבד גורם זה, שהוא המשען הראשון והאחרון לתקותנו בתנאי שיישאר בחיים אחרי מלחמה זו - הרי אמריקה היא הארץ העיקרית, שבה תבוצע משימתנו המדינית העיקרית בתקופה זו. פה נידונו הגורמים המדיניים הראשיים, אבל בל נזלזל בארצות האירופאיות, שיש'),\n",
       " Document(metadata={'book_id': 'memories', 'headline': 'ילדות ונעורים בפלונסק', 'source': 'DBGH', 'idx': 21529}, page_content='נולדתי ביום י\"ז בתשרי תרמ\"ז 16.10.1886 בעיירה קטנה בשם פלונסק, בפולין, שהיתה אז חלק של האימפריה הרוסית; עיירה זו נקראה בשם פלונסק, על שם הנהר פלונקה שעבר על-יד העיר. עיירה זו היתה תחילה מבצר של נסיך החבל, ובשנת 1400 העניק לה הנסיך מעמד של עיר. ידוע שעוד בשנת 1446 ישבו בה יהודים, שעסקו בעיקר במסחר ובעסקי כספים. בימי היתה פלונסק חלק של פלך ורשה, אולם לפני-כן היתה חלק מפלך פלוצק. במחצית השניה של המאה ה-17 גדל הישוב היהודי בפלונסק, בעקבות מלחמת פולין ושבדיה בשנת 1655. יהודי פלונסק נענשו על בגידת האצולה הפולנית שעברה בחלקה לצד של השבדים, רובם נהרגו ובתיהם נשרפו ורכושם נשדד ורוב העיר נשרף. בזמן הכיבוש הפרוסי בשנות 1794-1807 גדל הישוב היהודי בפלונסק, כי יהודים רבים שגרו בשטח פולני שנמסר לפרוסיה באו לגור בה, ובשנת 1808 כבר היו 2,801 יהודים בפלונסק, והם היו רוב תושבי העיר למעלה מ-73 אחוזים. בימים ההם זכתה פלונסק לשני יהודים רבי-עלילה: אחד שלמה פלונסקי נולד בפלונסק ב-1752 שביקר עוד בשנת 1821 בארץ-ישראל. אותה שנה היתה שנת המלחמה של היוונים נגד תורכיה בסיוע רוסיה. שליטי רוסיה ראו ביהודים ידידי תורכיה ואחד הקצינים הרוסים תפס את המכתבים, וכשבא שלמה פלונסקי לוורשה מיד נאסר, ונלקחו ממנו כל המכתבים שהביא אתו מארץ-ישראל לקרוביהם של יהודי ירושלים. חקירת שלמה פלונסקי בכלא נמשכה יותר משנתים, אולם לא יכלו להוציא ממנו תשובות פוליטיות כאשר ציפו. הוא נשאל אם זמן קיבוץ היהודים בירושלם הוא קרוב. הוא ענה שאי-אפשר לקבוע את הזמן בדיוק, אבל הוא לא רחוק. הממונה על החוק היה מוכן לשחררו ממאסרו, אבל שלמה נפטר בעודו בבית-הכלא. עד כמה שידוע היה שלמה פלונסקי הציוני הראשון בפולין, כפי שכתב פרופסור שמעון')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBGH_chunks[21527:21530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your-api-key\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea40d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_vectorstore_from_json(\n",
    "    original_index_path,\n",
    "    output_index_path,\n",
    "    wiki_chunks,\n",
    "    embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "):\n",
    "    # 1. Copy the original index directory\n",
    "    if os.path.exists(output_index_path):\n",
    "        raise FileExistsError(f\"{output_index_path} already exists. Choose a new path.\")\n",
    "    shutil.copytree(original_index_path, output_index_path)\n",
    "\n",
    "    # 2. Load the copied index as a new vectorstore\n",
    "    vectorstore = FAISS.load_local(output_index_path, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    # 3. Add new documents to the vectorstore\n",
    "    vectorstore.add_documents(wiki_chunks)\n",
    "    vectorstore.save_local(output_index_path)\n",
    "\n",
    "    print(f\"✅ Augmented vectorstore created at {output_index_path} with {len(wiki_chunks)} wiki chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd969329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmented vectorstore created at ./faiss_index_openai_3textlarge_full with 111 wiki chunks.\n"
     ]
    }
   ],
   "source": [
    "create_augmented_vectorstore_from_json(\"./faiss_index_openai_3textlarge\", \"./faiss_index_openai_3textlarge_full\", chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
