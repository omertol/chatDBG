{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b38a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "from DictaBERTEmbeddings import DictaBERTEmbeddings\n",
    "from query_prep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0519e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "# Load data\n",
    "pickle_file = os.path.join(DATA_PATH, 'prepd_data.pkl')\n",
    "data = pd.read_pickle(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f092a0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>type</th>\n",
       "      <th>unit</th>\n",
       "      <th>headline</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>lang</th>\n",
       "      <th>lemmatized_headline</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>document</th>\n",
       "      <th>lemmatized_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241112</td>\n",
       "      <td>ארכיון בן גוריון - מסמך</td>\n",
       "      <td>נאומים ומאמרים</td>\n",
       "      <td>חזון עתיד מתוקן, חגי ישראל, חזון הנביאים, תנופ...</td>\n",
       "      <td>ד. בן-גוריון    י\"ח אייר תש\"ט 17.5.49אין עמים ...</td>\n",
       "      <td>he</td>\n",
       "      <td>חזון עתיד תוקן , חג ישראל , חזון נביא , תנופה ...</td>\n",
       "      <td>ד . בן - גוריון י\"ח אייר תש\"ט 17 . 5 . 49 עם ר...</td>\n",
       "      <td>headline: חזון עתיד מתוקן, חגי ישראל, חזון הנב...</td>\n",
       "      <td>headline: חזון עתיד תוקן , חג ישראל , חזון נבי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241170</td>\n",
       "      <td>ארכיון בן גוריון - מסמך</td>\n",
       "      <td>נאומים ומאמרים</td>\n",
       "      <td>israel and the middle east, חברות ישראל באו\"ם,...</td>\n",
       "      <td>For Israel and Middle EastBy David Ben-Gurion ...</td>\n",
       "      <td>en</td>\n",
       "      <td>israel middle east חברות ישראל באו\"ם גלות בר כ...</td>\n",
       "      <td>israel middle eastby david ben gurion prime mi...</td>\n",
       "      <td>headline: israel and the middle east, חברות יש...</td>\n",
       "      <td>headline: israel middle east חברות ישראל באו\"ם...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241180</td>\n",
       "      <td>ארכיון בן גוריון - מסמך</td>\n",
       "      <td>נאומים ומאמרים</td>\n",
       "      <td>חוק שירות הביטחון</td>\n",
       "      <td>ישיבה ע' ו, 5.9.1949    חוק שירות הבטחון תש\"ט-...</td>\n",
       "      <td>he</td>\n",
       "      <td>חוק שירות ביטחון</td>\n",
       "      <td>ישיבה ע' ו , 5 . 9 . 1949 חוק שירות ביטחון תש\"...</td>\n",
       "      <td>headline: חוק שירות הביטחון, text: ישיבה ע' ו,...</td>\n",
       "      <td>headline: חוק שירות ביטחון, text: ישיבה ע' ו ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241225</td>\n",
       "      <td>ארכיון בן גוריון - מסמך</td>\n",
       "      <td>נאומים ומאמרים</td>\n",
       "      <td>how ambassador Morgenthau saved Palestine jewr...</td>\n",
       "      <td>HOW AMBASSADOR MORGENTHAU SAVED PALESTINE JEWR...</td>\n",
       "      <td>en</td>\n",
       "      <td>ambassador morgenthau save palestine jewry wor...</td>\n",
       "      <td>ambassador morgenthau save palestine jewry wor...</td>\n",
       "      <td>headline: how ambassador Morgenthau saved Pale...</td>\n",
       "      <td>headline: ambassador morgenthau save palestine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241459</td>\n",
       "      <td>ארכיון בן גוריון - מסמך</td>\n",
       "      <td>נאומים ומאמרים</td>\n",
       "      <td>[ח\"א?] במטה המורחב, צה\"ל, מערכת סיני, מלחמת סי...</td>\n",
       "      <td>12.12.57 ח\"א במטה המורחבאני מודה, שהדברים של מ...</td>\n",
       "      <td>he</td>\n",
       "      <td>[ ח\"א ? ] הטה מורחב , צה\"ל , מערכה סיני , מלחמ...</td>\n",
       "      <td>12 . 12 . 57 ח\"א הטה מורחב הודה , דבר משה , דב...</td>\n",
       "      <td>headline: [ח\"א?] במטה המורחב, צה\"ל, מערכת סיני...</td>\n",
       "      <td>headline: [ ח\"א ? ] הטה מורחב , צה\"ל , מערכה ס...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                     type            unit  \\\n",
       "0   241112  ארכיון בן גוריון - מסמך  נאומים ומאמרים   \n",
       "1   241170  ארכיון בן גוריון - מסמך  נאומים ומאמרים   \n",
       "2   241180  ארכיון בן גוריון - מסמך  נאומים ומאמרים   \n",
       "3   241225  ארכיון בן גוריון - מסמך  נאומים ומאמרים   \n",
       "4   241459  ארכיון בן גוריון - מסמך  נאומים ומאמרים   \n",
       "\n",
       "                                            headline  \\\n",
       "0  חזון עתיד מתוקן, חגי ישראל, חזון הנביאים, תנופ...   \n",
       "1  israel and the middle east, חברות ישראל באו\"ם,...   \n",
       "2                                  חוק שירות הביטחון   \n",
       "3  how ambassador Morgenthau saved Palestine jewr...   \n",
       "4  [ח\"א?] במטה המורחב, צה\"ל, מערכת סיני, מלחמת סי...   \n",
       "\n",
       "                                       combined_info lang  \\\n",
       "0  ד. בן-גוריון    י\"ח אייר תש\"ט 17.5.49אין עמים ...   he   \n",
       "1  For Israel and Middle EastBy David Ben-Gurion ...   en   \n",
       "2  ישיבה ע' ו, 5.9.1949    חוק שירות הבטחון תש\"ט-...   he   \n",
       "3  HOW AMBASSADOR MORGENTHAU SAVED PALESTINE JEWR...   en   \n",
       "4  12.12.57 ח\"א במטה המורחבאני מודה, שהדברים של מ...   he   \n",
       "\n",
       "                                 lemmatized_headline  \\\n",
       "0  חזון עתיד תוקן , חג ישראל , חזון נביא , תנופה ...   \n",
       "1  israel middle east חברות ישראל באו\"ם גלות בר כ...   \n",
       "2                                   חוק שירות ביטחון   \n",
       "3  ambassador morgenthau save palestine jewry wor...   \n",
       "4  [ ח\"א ? ] הטה מורחב , צה\"ל , מערכה סיני , מלחמ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  ד . בן - גוריון י\"ח אייר תש\"ט 17 . 5 . 49 עם ר...   \n",
       "1  israel middle eastby david ben gurion prime mi...   \n",
       "2  ישיבה ע' ו , 5 . 9 . 1949 חוק שירות ביטחון תש\"...   \n",
       "3  ambassador morgenthau save palestine jewry wor...   \n",
       "4  12 . 12 . 57 ח\"א הטה מורחב הודה , דבר משה , דב...   \n",
       "\n",
       "                                            document  \\\n",
       "0  headline: חזון עתיד מתוקן, חגי ישראל, חזון הנב...   \n",
       "1  headline: israel and the middle east, חברות יש...   \n",
       "2  headline: חוק שירות הביטחון, text: ישיבה ע' ו,...   \n",
       "3  headline: how ambassador Morgenthau saved Pale...   \n",
       "4  headline: [ח\"א?] במטה המורחב, צה\"ל, מערכת סיני...   \n",
       "\n",
       "                                 lemmatized_document  \n",
       "0  headline: חזון עתיד תוקן , חג ישראל , חזון נבי...  \n",
       "1  headline: israel middle east חברות ישראל באו\"ם...  \n",
       "2  headline: חוק שירות ביטחון, text: ישיבה ע' ו ,...  \n",
       "3  headline: ambassador morgenthau save palestine...  \n",
       "4  headline: [ ח\"א ? ] הטה מורחב , צה\"ל , מערכה ס...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bce98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe rows to LangChain Documents\n",
    "docs = [\n",
    "    Document(page_content=row['lemmatized_document'], metadata={\"id\": row['book_id']})\n",
    "    for idx, row in data.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_by_words(text, max_words, overlap_words):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(words):\n",
    "        end_idx = min(start_idx + max_words, len(words))\n",
    "        chunk = words[start_idx:end_idx]\n",
    "\n",
    "        # Join the words back into text\n",
    "        chunk_text = ' '.join(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "        # Update the starting position with overlap\n",
    "        start_idx += max_words - overlap_words\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3763b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for doc in docs:\n",
    "    temp_chunks = split_text_by_words(\n",
    "        doc.page_content, max_words=230, overlap_words=30\n",
    "    )\n",
    "    chunks.extend([Document(page_content=chunk, metadata=doc.metadata) for chunk in temp_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42c4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2467: 516 tokens\n",
      "Chunk 3314: 513 tokens\n",
      "Chunk 7447: 513 tokens\n",
      "Chunk 7448: 687 tokens\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dicta-il/dictabert\")\n",
    "j = 0\n",
    "for i, doc in enumerate(chunks):\n",
    "    tokens = tokenizer.encode(doc.page_content, truncation=False)\n",
    "    if (len(tokens) > 512):\n",
    "        j += 1\n",
    "        print(f\"Chunk {i}: {len(tokens)} tokens\")\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33f3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7912\n"
     ]
    }
   ],
   "source": [
    "# Check the number of chunks created\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc7ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dicta-il/dictabert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize DictaBERT embeddings\n",
    "embedding_model = DictaBERTEmbeddings(model_name=\"dicta-il/dictabert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b82822",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = os.path.join(DATA_PATH, 'embedding_dictaBERT.pkl')\n",
    "with open(EMB_PATH, 'wb') as f:\n",
    "    pickle.dump(embedding_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7480a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09277b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"./faiss_dicta_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a0941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index\n",
    "vectorstore = FAISS.load_local(\"./faiss_dicta_index\", \n",
    "                               embedding_model,\n",
    "                                allow_dangerous_deserialization=True\n",
    "                               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
